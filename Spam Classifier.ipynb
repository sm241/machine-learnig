{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "03_classification.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sm241/machine-learnig/blob/main/Spam%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DPaXiHGwN0D"
      },
      "source": [
        "**Ex_3.4 – Spam Classification**\n",
        "\n",
        "_ageron의 handson_ml2(github 소스 참고)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR3b3pnAwN0H"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/03_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsEVsH54wN0I"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op9wEWEIwN0I"
      },
      "source": [
        "\n",
        " 먼저, 몇 개의 공통 modul을 가져와 MatplotLib이 그림을 인라인으로 표시하는지 확인하고 그림을 저장하는 함수를 준비. 또한 Python 3.5 이상이 설치되어 있는지 확인, Scikit-Learn 0.20 이상 버전도 함께 설치."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7dfZfzwN0I"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQCzh4fCwN0k"
      },
      "source": [
        "## 4. Spam classifier(스팸 필터_머신러닝)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zqj80mzwN0k"
      },
      "source": [
        "1. 데이터 가져오기.(fetch the data:)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxF898QMwN0k"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
        "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
        "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
        "\n",
        "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
        "    if not os.path.isdir(spam_path):\n",
        "        os.makedirs(spam_path)\n",
        "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
        "        path = os.path.join(spam_path, filename)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "        tar_bz2_file = tarfile.open(path)\n",
        "        tar_bz2_file.extractall(path=spam_path)\n",
        "        tar_bz2_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nizL4t-bwN0k"
      },
      "source": [
        "fetch_spam_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D6W6pZtwN0l"
      },
      "source": [
        "2. 모든 email(데이터) 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKmHA6qjwN0l"
      },
      "source": [
        "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
        "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
        "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ASx7U78wN0l",
        "outputId": "ec43885e-0be3-4eb1-f63e-7238ffaf481c"
      },
      "source": [
        "len(ham_filenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPEHlHf_wN0l",
        "outputId": "8c60d7ea-d967-4b78-87ca-506455e8b409"
      },
      "source": [
        "len(spam_filenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHx746FKwN0l"
      },
      "source": [
        "Python의 'email' 모듈을 사용하여 전자 메일을 구문 분석할 수 있습니다(이것은 headers, encoding 등을 처리합니다)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2aC_99wN0l"
      },
      "source": [
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
        "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
        "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyk4PWIUwN0l"
      },
      "source": [
        "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
        "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgZLFwDiwN0m"
      },
      "source": [
        "Let's look at one example of ham and one example of spam, to get a feel of what the data looks like:\n",
        "(정상적인 메일고 스팸의 한 예들을 확인.) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQe82okwN0m",
        "outputId": "66850ddc-3219-4f81-ed33-7f7cb81da3e4"
      },
      "source": [
        "print(ham_emails[1].get_content().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Martin A posted:\n",
            "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
            " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
            " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
            " \n",
            " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
            " museum, a restored amphitheatre and car park for admiring crowds are\n",
            "planned\n",
            "---------------------\n",
            "So is this mountain limestone or granite?\n",
            "If it's limestone, it'll weather pretty fast.\n",
            "\n",
            "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
            "4 DVDs Free +s&p Join Now\n",
            "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
            "---------------------------------------------------------------------~->\n",
            "\n",
            "To unsubscribe from this group, send an email to:\n",
            "forteana-unsubscribe@egroups.com\n",
            "\n",
            " \n",
            "\n",
            "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boV484oXwN0m",
        "outputId": "73b6d3e2-0c0f-47db-9d04-338c7cad8324"
      },
      "source": [
        "print(spam_emails[6].get_content().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
            "growing at a tremendous rate.  We are looking for individuals who\n",
            "want to work from home.\n",
            "\n",
            "This is an opportunity to make an excellent income.  No experience\n",
            "is required.  We will train you.\n",
            "\n",
            "So if you are looking to be employed from home with a career that has\n",
            "vast opportunities, then go:\n",
            "\n",
            "http://www.basetel.com/wealthnow\n",
            "\n",
            "We are looking for energetic and self motivated people.  If that is you\n",
            "than click on the link and fill out the form, and one of our\n",
            "employement specialist will contact you.\n",
            "\n",
            "To be removed from our link simple go to:\n",
            "\n",
            "http://www.basetel.com/remove.html\n",
            "\n",
            "\n",
            "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiy3prDfwN0m"
      },
      "source": [
        "일부 전자 메일은 실제로 여러 부분으로, 이미지 및 첨부 파일(자체 첨부 파일이 있을 수 있음)이 있습니다. 아래 다양한 유형의 구조들이 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7H3h4qvwN0m"
      },
      "source": [
        "def get_email_structure(email):\n",
        "    if isinstance(email, str):\n",
        "        return email\n",
        "    payload = email.get_payload()\n",
        "    if isinstance(payload, list):\n",
        "        return \"multipart({})\".format(\", \".join([\n",
        "            get_email_structure(sub_email)\n",
        "            for sub_email in payload\n",
        "        ]))\n",
        "    else:\n",
        "        return email.get_content_type()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIuS2YpIwN0m"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "    structures = Counter()\n",
        "    for email in emails:\n",
        "        structure = get_email_structure(email)\n",
        "        structures[structure] += 1\n",
        "    return structures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4sOrSMrwN0m",
        "outputId": "197f5e1c-47ed-4701-a58f-caecab791612"
      },
      "source": [
        "structures_counter(ham_emails).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2408),\n",
              " ('multipart(text/plain, application/pgp-signature)', 66),\n",
              " ('multipart(text/plain, text/html)', 8),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRkiEW1RwN0m",
        "outputId": "ac5f1445-4811-4612-83f9-4d040d6e3e8d"
      },
      "source": [
        "structures_counter(spam_emails).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 218),\n",
              " ('text/html', 183),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 20),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCzDTqFowN0n"
      },
      "source": [
        "It seems that the ham emails are more often plain text, while spam has quite a lot of HTML. Moreover, quite a few ham emails are signed using PGP, while no spam is. (정상메일과 스팸 메일을 구분할 수 있는 기준 설명) 즉, 이 예시는 데이터로 쓰기 적당함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KAzqyFpwN0n"
      },
      "source": [
        "전자 메일 header를 보면:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhxXWu1swN0n",
        "outputId": "d8ff1ea1-6a71-4912-f2d2-87a0ffb7f097"
      },
      "source": [
        "for header, value in spam_emails[0].items():\n",
        "    print(header,\":\",value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Return-Path : <12a1mailbot1@web.de>\n",
            "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
            "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
            "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
            "From : 12a1mailbot1@web.de\n",
            "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
            "To : dcek1a1@netsgo.com\n",
            "Subject : Life Insurance - Why Pay More?\n",
            "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
            "MIME-Version : 1.0\n",
            "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
            "Content-Type : text/html; charset=\"iso-8859-1\"\n",
            "Content-Transfer-Encoding : quoted-printable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlDj_5nlwN0n"
      },
      "source": [
        "발신자 이메일 주소(12a1mailbot1@web.de)가 수상해 보이는 등의 많은 정보들이 있겟지만 이메일 제목(the `Subject` header)만 볼 예정:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIlFgrKHwN0n",
        "outputId": "7caf01e2-c6c9-428f-ef0a-4d64ca322ef0"
      },
      "source": [
        "spam_emails[0][\"Subject\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Life Insurance - Why Pay More?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy6HeNTNwN0o"
      },
      "source": [
        "training set과 test set으로 나누기:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kogtbX6wN0o"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails, dtype=object)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428HdbhuwN0o"
      },
      "source": [
        " 이제 전처리 기능들을 작성. 먼저 HTML을 일반 텍스트로 변환하는 기능이 필요. 가장 좋은 방법은 훌륭한 [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) 라이브러리)를 사용하는 것이지만, 이 프로젝트에 다른 종속성이 추가되는 것을 피하고자, 정규 표현식을 사용하여 솔루션을 해킹해 봅시다([모든 권한의 파괴를 무릅쓰고].https://stackoverflow.com/a/1732454/38626)). 다음 함수는 1.\"<head>\" 부분을 삭제 2. 모든 \"a\" 태그를 하이퍼링크라는 단어로 변환한다. 3. 모든 HTML 태그를 제거하고 일반 텍스트만 남긴다. 4. 가독성을 위해 여러 개의 새 줄을 하나의 새 줄로 대체. 4. html 엔터티(예: \"&gt;\" 또는 \"&nbsp;\")를 해제."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGnsOiU2wN0o"
      },
      "source": [
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plain_text(html):\n",
        "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "    return unescape(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sZsb3d6wN0o"
      },
      "source": [
        "잘 작동하는지 체크 아래가 HTML spam이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsn1MmelwN0o",
        "outputId": "459f425e-773c-4eaa-a616-a9dbb1684102"
      },
      "source": [
        "html_spam_emails = [email for email in X_train[y_train==1]\n",
        "                    if get_email_structure(email) == \"text/html\"]\n",
        "sample_html_spam = html_spam_emails[7]\n",
        "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
            "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
            "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
            "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
            "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
            "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
            "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PTjlUbbwN0o"
      },
      "source": [
        "그리고 아래가 plain text의 결과이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTvKvf92wN0p",
        "outputId": "dfb3d636-ec6a-4f51-b0c3-fc2fabdada88"
      },
      "source": [
        "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
            "Put CBYI on your watch list, acquire a position TODAY.\n",
            "REASONS TO INVEST IN CBYI\n",
            "A profitable company and is on track to beat ALL earnings estimates!\n",
            "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
            "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
            "RAPIDLY GROWING INDUSTRY\n",
            "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5SARy0HwN0p"
      },
      "source": [
        "잘 작동되는것을 확인했음. 이제 전자 메일을 입력으로 사용하고 전자 메일의 형식이 무엇이든 일반 텍스트로 내용을 반환하는 기능을 작성:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrrbkIJuwN0p"
      },
      "source": [
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in (\"text/plain\", \"text/html\"):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # in case of encoding issues\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == \"text/plain\":\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html_to_plain_text(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3lKwdhEwN0p",
        "outputId": "f6aa14f0-16bf-4be2-cf0d-751fc303c33f"
      },
      "source": [
        "print(email_to_text(sample_html_spam)[:100], \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Wat ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQZaqdWhwN0p"
      },
      "source": [
        "Let's throw in some stemming! 이렇게 하려면 자연어 툴킷([NLTK](http://www.nltk.org/)))을 설치해야 합니다. 다음 명령을 실행하는 것만큼 간단합니다. 먼저 가상 환경을 활성화해야 합니다. 가상 환경이 없으면 관리자 권한이 필요하거나 '-user' 옵션을 사용해야 합니다.\n",
        "\n",
        "\"$ pip3 install nltk\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPUjLW4JwN0p",
        "outputId": "534cceeb-6c34-4b2c-e5f2-1f33e51cc073"
      },
      "source": [
        "try:\n",
        "    import nltk\n",
        "\n",
        "    stemmer = nltk.PorterStemmer()\n",
        "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
        "        print(word, \"=>\", stemmer.stem(word))\n",
        "except ImportError:\n",
        "    print(\"Error: stemming requires the NLTK module.\")\n",
        "    stemmer = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZtnxF96wN0p"
      },
      "source": [
        "우리는 또한 URL을 \"URL\"이라는 단어로 대체할 방법이 필요할 것. 이를 위해 우리는 하드코어 [정규 표현](https://mathiasbynens.be/demo/url-regex)을 사용할 수 있지만, [url extract](https://github.com/lipoja/URLExtract) 라이브러리만 사용할 것이다. 다음 명령으로 설치할 수 있습니다. 먼저 가상 환경을 활성화해야 합니다. 없으면 관리자 권한이 필요하거나 '--user' 옵션을 사용해야 합니다.\n",
        "\n",
        "\"$ pip3 install urlextract\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0885YUscwN0p"
      },
      "source": [
        "# if running this notebook on Colab, we just pip install urlextract\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install -q -U urlextract\n",
        "except ImportError:\n",
        "    pass # not running on Colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDc5hX7vwN0q",
        "outputId": "5e4cf7da-a48f-4dbf-e2ac-cceffc8909db"
      },
      "source": [
        "try:\n",
        "    import urlextract # may require an Internet connection to download root domain names\n",
        "    \n",
        "    url_extractor = urlextract.URLExtract()\n",
        "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
        "except ImportError:\n",
        "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
        "    url_extractor = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmsWkZb4wN0q"
      },
      "source": [
        " 우리는 이메일을 워드 카운터로 변환하는 데 사용할 변압기로 이 모든 것을 통합할 준비 끝! cf. 우리는 단어 경계에 공백을 사용하는 파이썬의 \"split()\" 방법을 사용하여 문장을 단어로 분할한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYN7FvkAwN0q"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
        "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
        "        self.strip_headers = strip_headers\n",
        "        self.lower_case = lower_case\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.replace_urls = replace_urls\n",
        "        self.replace_numbers = replace_numbers\n",
        "        self.stemming = stemming\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for email in X:\n",
        "            text = email_to_text(email) or \"\"\n",
        "            if self.lower_case:\n",
        "                text = text.lower()\n",
        "            if self.replace_urls and url_extractor is not None:\n",
        "                urls = list(set(url_extractor.find_urls(text)))\n",
        "                urls.sort(key=lambda url: len(url), reverse=True)\n",
        "                for url in urls:\n",
        "                    text = text.replace(url, \" URL \")\n",
        "            if self.replace_numbers:\n",
        "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "            if self.remove_punctuation:\n",
        "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "            word_counts = Counter(text.split())\n",
        "            if self.stemming and stemmer is not None:\n",
        "                stemmed_word_counts = Counter()\n",
        "                for word, count in word_counts.items():\n",
        "                    stemmed_word = stemmer.stem(word)\n",
        "                    stemmed_word_counts[stemmed_word] += count\n",
        "                word_counts = stemmed_word_counts\n",
        "            X_transformed.append(word_counts)\n",
        "        return np.array(X_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvQiCTLrwN0q"
      },
      "source": [
        "몇개의 이메일을 변환해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joWOYD7MwN0q",
        "outputId": "1d9b5018-0229-44fb-d407-6b13b1add230"
      },
      "source": [
        "X_few = X_train[:3]\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
        "X_few_wordcounts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
              "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
              "       Counter({'url': 4, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'com': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1})],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_-gSIJwN0q"
      },
      "source": [
        "이제 우리는 단어 수를 가지고 있고, 그것들을 벡터로 변환해야 합니다. 이를 위해, 우리는 \"fit()\" 방법이 어휘(가장 일반적인 단어의 순서 목록)를 작성하고, \"transform()\" 방법이 어휘를 사용하여 단어 수를 벡터로 변환하는 또 다른 변압기를 구축. 이때, 출력은 sparse matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPqnW7r7wN0r"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, vocabulary_size=1000):\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "    def fit(self, X, y=None):\n",
        "        total_count = Counter()\n",
        "        for word_count in X:\n",
        "            for word, count in word_count.items():\n",
        "                total_count[word] += min(count, 10)\n",
        "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        rows = []\n",
        "        cols = []\n",
        "        data = []\n",
        "        for row, word_count in enumerate(X):\n",
        "            for word, count in word_count.items():\n",
        "                rows.append(row)\n",
        "                cols.append(self.vocabulary_.get(word, 0))\n",
        "                data.append(count)\n",
        "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZB6WryBwN0r",
        "outputId": "60541433-0dec-4170-ccf9-5fbe4e1ba079"
      },
      "source": [
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x11 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 20 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNw6Q4xiwN0r",
        "outputId": "34616c7e-02bf-4880-ff75-db46dcb0a3fd"
      },
      "source": [
        "X_few_vectors.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [99, 11,  9,  8,  3,  1,  3,  1,  3,  2,  3],\n",
              "       [67,  0,  1,  2,  3,  4,  1,  2,  0,  1,  0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od-Vl4iqwN0r"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTzWHniwN0r",
        "outputId": "883c4c43-3b8e-430b-a632-3e0909d23482"
      },
      "source": [
        "vocab_transformer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'and': 3,\n",
              " 'to': 4,\n",
              " 'url': 5,\n",
              " 'all': 6,\n",
              " 'in': 7,\n",
              " 'christian': 8,\n",
              " 'on': 9,\n",
              " 'by': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfqLNYUewN0r"
      },
      "source": [
        "이제 첫 번째 스팸 분류기를 교육시킬 준비완료! 전체 데이터 세트를 변환:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_trIRzMwN0r"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hS4750jwN0r"
      },
      "source": [
        "**Note**:to be future-proof, we set `solver=\"lbfgs\"` since this will be the default value in Scikit-Learn 0.22."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnTkV-WpwN0r",
        "outputId": "560ab06d-9d54-4f81-d15e-f65f637fe698"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
        "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.981, total=   0.1s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.985, total=   0.2s\n",
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.991, total=   0.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9858333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc_avl4IwN0s"
      },
      "source": [
        "결과는 98.5% 이상 (\"쉬운\" 데이터 세트를 사용하고 있어서 높게 나온것. 더 어려운 데이터 세트를 사용해 보면 결과는 그리 높게 나오지 않을것이다.) 여러 모형을 시도하고 가장 적합한 모형을 선택한 다음 교차 검증을 사용하여 모형을 미세 조정 필요.\n",
        "\n",
        "이제 테스트 세트의 percision/recall을 print:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1FIxz0FwN0s",
        "outputId": "d84d971f-4984-441c-abf3-d16533e19521"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "\n",
        "y_pred = log_clf.predict(X_test_transformed)\n",
        "\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 95.88%\n",
            "Recall: 97.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QZZb-KRwN0s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}